{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class basket_MGU(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for the basket MGU without covariates\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seq_length, input_dim, num_hidden):\n",
    "        \"\"\"\n",
    "        Initializes a basket_MGU instance\n",
    "\n",
    "        Arguments:\n",
    "          seq_length    number of time steps in each (padded) sequence, scalar\n",
    "          input_dim     dimensionality of the MGU input (equals the assortment size here)\n",
    "          num_hidden    dimensionality of the hidden MGU state, scalar hyperparameter\n",
    "        \"\"\"\n",
    "        super(basket_MGU, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.input_dim = input_dim\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "        self.h_init = torch.zeros(num_hidden)\n",
    "\n",
    "        # Minimal Gated Unit (MGU) parameters\n",
    "        self.W_ux = nn.Parameter(torch.Tensor(input_dim, num_hidden))\n",
    "        nn.init.xavier_uniform_(self.W_ux.data)\n",
    "        self.W_uh = nn.Parameter(torch.Tensor(num_hidden, num_hidden))\n",
    "        nn.init.xavier_uniform_(self.W_uh.data)\n",
    "        self.b_u = nn.Parameter(torch.zeros(num_hidden))\n",
    "\n",
    "        self.W_rx = nn.Parameter(torch.Tensor(input_dim, num_hidden))\n",
    "        nn.init.xavier_uniform_(self.W_rx.data)\n",
    "        self.W_rh = nn.Parameter(torch.Tensor(num_hidden, num_hidden))\n",
    "        nn.init.xavier_uniform_(self.W_rh.data)\n",
    "        self.b_r = nn.Parameter(torch.zeros(num_hidden))\n",
    "\n",
    "        self.W_cx = nn.Parameter(torch.Tensor(input_dim, num_hidden))\n",
    "        nn.init.xavier_uniform_(self.W_cx.data)\n",
    "        self.W_ch = nn.Parameter(torch.Tensor(num_hidden, num_hidden))\n",
    "        nn.init.xavier_uniform_(self.W_ch.data)\n",
    "        self.b_c = nn.Parameter(torch.zeros(num_hidden))\n",
    "\n",
    "        # Output layer parameters\n",
    "        self.W_ph = nn.Parameter(torch.Tensor(num_hidden, input_dim))\n",
    "        nn.init.xavier_uniform_(self.W_ph.data)\n",
    "        self.b_p = nn.Parameter(torch.zeros(input_dim))\n",
    "\n",
    "    def forward(self, x, fw_dropout=False, rc_dropout=False, stepwise=False, track_hiddens=False):\n",
    "        \"\"\"\n",
    "        Executes a forward step of the basket MGU model, for a given input x\n",
    "\n",
    "        Arguments:\n",
    "          x               batch of input sequences ([batch size] x [sequence length] x [assortment size])\n",
    "          fw_dropout      dropout rate to apply in the forward layer (either False (0, default) or a scalar value between 0 and 1)\n",
    "          rc_dropout      dropout rate to apply in the input gate (either False (0, default) or a scalar value between 0 and 1)\n",
    "          stepwise        whether to drop out different nodes in each time step (True) or the same nodes in every time step (False, default)\n",
    "          track_hiddens   whether to return the hidden states computed in each time step (default is False)\n",
    "        \"\"\"\n",
    "        fw_dropout_rate = 0\n",
    "        rc_dropout_rate = 0\n",
    "\n",
    "        if track_hiddens:\n",
    "            hiddens = torch.zeros(x.size()[0], x.size()[1], self.num_hidden)\n",
    "\n",
    "        if fw_dropout != False:\n",
    "            fw_dropout_rate = fw_dropout\n",
    "\n",
    "        if rc_dropout != False:\n",
    "            rc_dropout_rate = rc_dropout\n",
    "\n",
    "        hidden = self.h_init.to(device)\n",
    "\n",
    "        if stepwise == False:\n",
    "            fw_dropout_mask = torch.bernoulli(torch.ones(x.size()[0], self.input_dim) - fw_dropout_rate) / (\n",
    "                    1 - fw_dropout_rate)\n",
    "            rc_dropout_mask = torch.bernoulli(torch.ones(x.size()[0], self.num_hidden) - rc_dropout_rate) / (\n",
    "                    1 - rc_dropout_rate)\n",
    "\n",
    "        pred_sequence = torch.zeros(x.size()[0], x.size()[1], self.input_dim)\n",
    "\n",
    "        for t in np.arange(x.size()[1]):\n",
    "            if stepwise == True:\n",
    "                fw_dropout_mask = torch.bernoulli(torch.ones(x.size()[0], self.input_dim) - fw_dropout_rate) / (\n",
    "                        1 - fw_dropout_rate)\n",
    "                rc_dropout_mask = torch.bernoulli(torch.ones(x.size()[0], self.num_hidden) - rc_dropout_rate) / (\n",
    "                        1 - rc_dropout_rate)\n",
    "\n",
    "            xt = x[:, t, :]  # xt should have dimensions [batch_size, input_dim]\n",
    "\n",
    "            if fw_dropout != False:\n",
    "                xt = xt * fw_dropout_mask\n",
    "\n",
    "            update_gate = torch.sigmoid(\n",
    "                torch.matmul(xt, self.W_ux) + torch.matmul(hidden, self.W_uh) + self.b_u)\n",
    "            reset_gate = torch.sigmoid(\n",
    "                torch.matmul(xt, self.W_rx) + torch.matmul(hidden, self.W_rh) + self.b_r)\n",
    "            candidate_gate = torch.tanh(\n",
    "                torch.matmul(xt, self.W_cx) + torch.matmul(reset_gate * hidden, self.W_ch) + self.b_c)\n",
    "\n",
    "            if rc_dropout != False:\n",
    "                candidate_gate = candidate_gate * rc_dropout_mask\n",
    "\n",
    "            hidden = (1 - update_gate) * hidden + update_gate * candidate_gate\n",
    "\n",
    "            if track_hiddens:\n",
    "                hiddens[:, t, :] = hidden\n",
    "\n",
    "            next_basket = torch.sigmoid(torch.matmul(hidden, self.W_ph) + self.b_p)\n",
    "            pred_sequence[:, t, :] = next_basket\n",
    "\n",
    "        if track_hiddens:\n",
    "            return pred_sequence, hiddens\n",
    "        else:\n",
    "            return pred_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
